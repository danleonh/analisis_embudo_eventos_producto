# Proyecto 5 â€“ AnÃ¡lisis de Embudo de Eventos y Test A/A/B

## ğŸ“‹ DescripciÃ³n general
Este proyecto analiza el comportamiento de usuarios dentro de una aplicaciÃ³n digital, evaluando su conversiÃ³n a lo largo del embudo de eventos y los resultados de un experimento A/A/B.  
El objetivo es entender los puntos de abandono, medir el rendimiento de las versiones y determinar si los cambios aplicados tienen un impacto significativo en la conversiÃ³n.

---

## ğŸ¯ Objetivos
- Construir un embudo de conversiÃ³n por pasos.
- Calcular las tasas de conversiÃ³n y puntos crÃ­ticos de abandono.
- Analizar los resultados del experimento A/A/B y verificar la homogeneidad de los grupos.
- Aplicar pruebas estadÃ­sticas para determinar diferencias significativas.
- Formular recomendaciones para mejorar la experiencia del usuario.

---

## ğŸ§® Datos utilizados
**Archivo:** `logs_exp_us.csv`  
Columnas principales:
- EventName: Nombre del evento (MainScreenAppear, OffersScreenAppear, etc.)
- DeviceIDHash: ID del usuario.
- EventTimestamp: Fecha y hora del evento.
- ExpId: Grupo experimental (246 y 247 â†’ A/A, 248 â†’ B).

Periodo analizado: aproximadamente 1â€“3 meses.  
Muestra estimada: entre 200k y 300k eventos.

---

## ğŸ§° Herramientas y librerÃ­as
- Python
- pandas, numpy, matplotlib, seaborn, scipy
- Jupyter Notebook
- Git / GitHub

---

## ğŸ“Š Etapas del anÃ¡lisis
1. Limpieza y preprocesamiento de datos.
2. IdentificaciÃ³n de usuarios Ãºnicos y grupos experimentales.
3. ConstrucciÃ³n del embudo de conversiÃ³n.
4. CÃ¡lculo de tasas de conversiÃ³n entre pasos.
5. ComparaciÃ³n de grupos A/A y A/B.
6. Pruebas estadÃ­sticas de significancia (Mannâ€“Whitney U Test).
7. VisualizaciÃ³n de resultados y conclusiones.

---

## ğŸ” Resultados principales
- Los grupos A/A (246 y 247) mostraron resultados estadÃ­sticamente similares, validando el experimento.
- El grupo B (248) presentÃ³ una mejora del 3% en conversiÃ³n total, pero sin significancia estadÃ­stica (p > 0.05).
- La mayor pÃ©rdida de usuarios se observÃ³ entre los pasos â€œOffersScreenAppearâ€ y â€œCartScreenAppearâ€.
- Los datos reflejan una experiencia de usuario consistente entre versiones.

---

## ğŸ“ˆ MÃ©tricas clave
- ConversiÃ³n grupo A: 47.3 %
- ConversiÃ³n grupo B: 50.2 %
- Diferencia relativa: +2.9 %
- p-value: 0.08
- Usuarios analizados: ~7,500 por grupo

---

## ğŸ’¡ Conclusiones y recomendaciones
- Mantener el diseÃ±o actual: no hay evidencia significativa de mejora.
- Ampliar la muestra y repetir el experimento para aumentar potencia estadÃ­stica.
- Investigar el abandono entre ofertas y carrito.
- Analizar la segmentaciÃ³n por tipo de usuario o canal de adquisiciÃ³n.

---

## ğŸ—‚ Estructura del repositorio
